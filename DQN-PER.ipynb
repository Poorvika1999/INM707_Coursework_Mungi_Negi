{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of DQN_PER.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xn-PKGaNTj0f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import math\n",
        "import operator\n",
        "\n",
        "from collections import namedtuple, deque\n",
        "from numpy.random import choice\n",
        "\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "#from pyvirtualdisplay import Display"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install box2d-py\n",
        "!pip3 install gym[Box_2D]\n",
        "import gym\n",
        "env = gym.make(\"LunarLander-v2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQrXgj2yTk3R",
        "outputId": "9463e963-369e-4466-c589-c03b4bb0455e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting box2d-py\n",
            "  Downloading box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 19.1 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 25.2 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 30 kB 15.3 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 51 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 61 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 71 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 81 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 92 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 102 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████                        | 112 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 122 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 133 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 143 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 153 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 163 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 174 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 184 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 194 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 204 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 215 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 225 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 235 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 245 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 256 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 266 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 276 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 286 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 296 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 307 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 317 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 327 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 337 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 348 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 358 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 368 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 378 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 389 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 399 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 409 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 419 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 430 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 440 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 448 kB 8.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: box2d-py\n",
            "Successfully installed box2d-py-2.3.8\n",
            "Requirement already satisfied: gym[Box_2D] in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "\u001b[33mWARNING: gym 0.17.3 does not provide the extra 'box_2d'\u001b[0m\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[Box_2D]) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = int(1e5)      # replay buffer size\n",
        "BATCH_SIZE = 64             # minibatch size\n",
        "GAMMA = 0.99                # discount factor\n",
        "TAU = 1e-3                  # for soft update of target parameters\n",
        "LR = 5e-4                   # learning rate \n",
        "UPDATE_NN_EVERY = 1        # how often to update the network\n"
      ],
      "metadata": {
        "id": "QyBd3wDQTod2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QNetwork(nn.Module):\n",
        "    \"\"\"Actor (Policy) Model.\"\"\"\n",
        "\n",
        "    def __init__(self, state_size, action_size, seed):\n",
        "        \"\"\"Initialize parameters and build model.\n",
        "        Params\n",
        "        ======\n",
        "            state_size (int): Dimension of each state\n",
        "            action_size (int): Dimension of each action\n",
        "            seed (int): Random seed\n",
        "        \"\"\"\n",
        "        super(QNetwork, self).__init__()\n",
        "        self.seed = torch.manual_seed(seed)\n",
        "        self.fc1 = nn.Linear(state_size, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, action_size)\n",
        "\n",
        "        \n",
        "\n",
        "    def forward(self, state):\n",
        "        x = F.relu(self.fc1(state))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return self.fc3(x)"
      ],
      "metadata": {
        "id": "DAR53ZMlTtuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "class ReplayBuffer:\n",
        "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
        "\n",
        "    def __init__(self, action_size, buffer_size, batch_size, experiences_per_sampling, seed, compute_weights):\n",
        "        \"\"\"Initialize a ReplayBuffer object.\n",
        "        Params\n",
        "        ======\n",
        "            action_size (int): dimension of each action\n",
        "            buffer_size (int): maximum size of buffer\n",
        "            experiences_per_sampling (int): number of experiences to sample during a sampling iteration\n",
        "            batch_size (int): size of each training batch\n",
        "            seed (int): random seed\n",
        "        \"\"\"\n",
        "        self.action_size = action_size\n",
        "        self.buffer_size = buffer_size\n",
        "        self.batch_size = batch_size\n",
        "        self.experiences_per_sampling = experiences_per_sampling\n",
        "        \n",
        "        self.alpha = 0.5\n",
        "        self.alpha_decay_rate = 0.99\n",
        "        self.beta = 0.5\n",
        "        self.beta_growth_rate = 1.001\n",
        "        self.seed = random.seed(seed)\n",
        "        self.compute_weights = compute_weights\n",
        "        self.experience_count = 0\n",
        "        \n",
        "        self.experience = namedtuple(\"Experience\", \n",
        "            field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
        "        self.data = namedtuple(\"Data\", \n",
        "            field_names=[\"priority\", \"probability\", \"weight\",\"index\"])\n",
        "\n",
        "        indexes = []\n",
        "        datas = []\n",
        "        for i in range(buffer_size):\n",
        "            indexes.append(i)\n",
        "            d = self.data(0,0,0,i)\n",
        "            datas.append(d)\n",
        "        \n",
        "        self.memory = {key: self.experience for key in indexes}\n",
        "        self.memory_data = {key: data for key,data in zip(indexes, datas)}\n",
        "        self.sampled_batches = []\n",
        "        self.current_batch = 0\n",
        "        self.priorities_sum_alpha = 0\n",
        "        self.priorities_max = 1\n",
        "        self.weights_max = 1\n",
        "    \n",
        "    def update_priorities(self, tds, indices):\n",
        "        for td, index in zip(tds, indices):\n",
        "            N = min(self.experience_count, self.buffer_size)\n",
        "\n",
        "            updated_priority = td[0]\n",
        "            if updated_priority > self.priorities_max:\n",
        "                self.priorities_max = updated_priority\n",
        "            \n",
        "            if self.compute_weights:\n",
        "                updated_weight = ((N * updated_priority)**(-self.beta))/self.weights_max\n",
        "                if updated_weight > self.weights_max:\n",
        "                    self.weights_max = updated_weight\n",
        "            else:\n",
        "                updated_weight = 1\n",
        "\n",
        "            old_priority = self.memory_data[index].priority\n",
        "            self.priorities_sum_alpha += updated_priority**self.alpha - old_priority**self.alpha\n",
        "            updated_probability = td[0]**self.alpha / self.priorities_sum_alpha\n",
        "            data = self.data(updated_priority, updated_probability, updated_weight, index) \n",
        "            self.memory_data[index] = data\n",
        "\n",
        "    def update_memory_sampling(self):\n",
        "        \"\"\"Randomly sample X batches of experiences from memory.\"\"\"\n",
        "        # X is the number of steps before updating memory\n",
        "        self.current_batch = 0\n",
        "        values = list(self.memory_data.values())\n",
        "        random_values = random.choices(self.memory_data, \n",
        "                                       [data.probability for data in values], \n",
        "                                       k=self.experiences_per_sampling)\n",
        "        self.sampled_batches = [random_values[i:i + self.batch_size] \n",
        "                                    for i in range(0, len(random_values), self.batch_size)]\n",
        "\n",
        "    def update_parameters(self):\n",
        "        self.alpha *= self.alpha_decay_rate\n",
        "        self.beta *= self.beta_growth_rate\n",
        "        if self.beta > 1:\n",
        "            self.beta = 1\n",
        "        N = min(self.experience_count, self.buffer_size)\n",
        "        self.priorities_sum_alpha = 0\n",
        "        sum_prob_before = 0\n",
        "        for element in self.memory_data.values():\n",
        "            sum_prob_before += element.probability\n",
        "            self.priorities_sum_alpha += element.priority**self.alpha\n",
        "        sum_prob_after = 0\n",
        "        for element in self.memory_data.values():\n",
        "            probability = element.priority**self.alpha / self.priorities_sum_alpha\n",
        "            sum_prob_after += probability\n",
        "            weight = 1\n",
        "            if self.compute_weights:\n",
        "                weight = ((N *  element.probability)**(-self.beta))/self.weights_max\n",
        "            d = self.data(element.priority, probability, weight, element.index)\n",
        "            self.memory_data[element.index] = d\n",
        "        print(\"sum_prob before\", sum_prob_before)\n",
        "        print(\"sum_prob after : \", sum_prob_after)\n",
        "    \n",
        "    def add(self, state, action, reward, next_state, done):\n",
        "        \"\"\"Add a new experience to memory.\"\"\"\n",
        "        self.experience_count += 1\n",
        "        index = self.experience_count % self.buffer_size\n",
        "\n",
        "        if self.experience_count > self.buffer_size:\n",
        "            temp = self.memory_data[index]\n",
        "            self.priorities_sum_alpha -= temp.priority**self.alpha\n",
        "            if temp.priority == self.priorities_max:\n",
        "                self.memory_data[index].priority = 0\n",
        "                self.priorities_max = max(self.memory_data.items(), key=operator.itemgetter(1)).priority\n",
        "            if self.compute_weights:\n",
        "                if temp.weight == self.weights_max:\n",
        "                    self.memory_data[index].weight = 0\n",
        "                    self.weights_max = max(self.memory_data.items(), key=operator.itemgetter(2)).weight\n",
        "\n",
        "        priority = self.priorities_max\n",
        "        weight = self.weights_max\n",
        "        self.priorities_sum_alpha += priority ** self.alpha\n",
        "        probability = priority ** self.alpha / self.priorities_sum_alpha\n",
        "        e = self.experience(state, action, reward, next_state, done)\n",
        "        self.memory[index] = e\n",
        "        d = self.data(priority, probability, weight, index)\n",
        "        self.memory_data[index] = d\n",
        "            \n",
        "    def sample(self):\n",
        "        sampled_batch = self.sampled_batches[self.current_batch]\n",
        "        self.current_batch += 1\n",
        "        experiences = []\n",
        "        weights = []\n",
        "        indices = []\n",
        "        \n",
        "        for data in sampled_batch:\n",
        "            experiences.append(self.memory.get(data.index))\n",
        "            weights.append(data.weight)\n",
        "            indices.append(data.index)\n",
        "\n",
        "        states = torch.from_numpy(\n",
        "            np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
        "        actions = torch.from_numpy(\n",
        "            np.vstack([e.action for e in experiences if e is not None])).long().to(device)\n",
        "        rewards = torch.from_numpy(\n",
        "            np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
        "        next_states = torch.from_numpy(\n",
        "            np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
        "        dones = torch.from_numpy(\n",
        "            np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
        "\n",
        "        return (states, actions, rewards, next_states, dones, weights, indices)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return the current size of internal memory.\"\"\"\n",
        "        return len(self.memory)"
      ],
      "metadata": {
        "id": "GD4jOCkUTwyp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95413514-1595-4d79-aa60-ec2374428c2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prioritized experience replay\n",
        "UPDATE_MEM_EVERY = 20          # how often to update the priorities\n",
        "UPDATE_MEM_PAR_EVERY = 3000     # how often to update the hyperparameters\n",
        "EXPERIENCES_PER_SAMPLING = math.ceil(BATCH_SIZE * UPDATE_MEM_EVERY / UPDATE_NN_EVERY)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class Agent():\n",
        "    \"\"\"Interacts with and learns from the environment.\"\"\"\n",
        "\n",
        "    def __init__(self, state_size, action_size, seed, compute_weights = False):\n",
        "        \"\"\"Initialize an Agent object.\n",
        "        \n",
        "        Params\n",
        "        ======\n",
        "            state_size (int): dimension of each state\n",
        "            action_size (int): dimension of each action\n",
        "            seed (int): random seed\n",
        "        \"\"\"\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.seed = random.seed(seed)\n",
        "        self.compute_weights = compute_weights\n",
        "\n",
        "        # Q-Network\n",
        "        self.qnetwork_local = QNetwork(state_size, action_size, seed).to(device)\n",
        "        self.qnetwork_target = QNetwork(state_size, action_size, seed).to(device)\n",
        "        self.optimizer = optim.Adam(self.qnetwork_local.parameters(), lr=LR)\n",
        "        self.criterion = nn.MSELoss()\n",
        "\n",
        "        # Replay memory\n",
        "        self.memory = ReplayBuffer(\n",
        "            action_size, BUFFER_SIZE, BATCH_SIZE, EXPERIENCES_PER_SAMPLING, seed, compute_weights)\n",
        "        # Initialize time step (for updating every UPDATE_NN_EVERY steps)\n",
        "        self.t_step_nn = 0\n",
        "        # Initialize time step (for updating every UPDATE_MEM_PAR_EVERY steps)\n",
        "        self.t_step_mem_par = 0\n",
        "        # Initialize time step (for updating every UPDATE_MEM_EVERY steps)\n",
        "        self.t_step_mem = 0\n",
        "    \n",
        "    def step(self, state, action, reward, next_state, done):\n",
        "        # Save experience in replay memory\n",
        "        self.memory.add(state, action, reward, next_state, done)\n",
        "        \n",
        "        # Learn every UPDATE_NN_EVERY time steps.\n",
        "        self.t_step_nn = (self.t_step_nn + 1) % UPDATE_NN_EVERY\n",
        "        self.t_step_mem = (self.t_step_mem + 1) % UPDATE_MEM_EVERY\n",
        "        self.t_step_mem_par = (self.t_step_mem_par + 1) % UPDATE_MEM_PAR_EVERY\n",
        "        if self.t_step_mem_par == 0:\n",
        "            self.memory.update_parameters()\n",
        "        if self.t_step_nn == 0:\n",
        "            # If enough samples are available in memory, get random subset and learn\n",
        "            if self.memory.experience_count > EXPERIENCES_PER_SAMPLING:\n",
        "                sampling = self.memory.sample()\n",
        "                self.learn(sampling, GAMMA)\n",
        "        if self.t_step_mem == 0:\n",
        "            self.memory.update_memory_sampling()\n",
        "\n",
        "    def act(self, state, eps=0.):\n",
        "        \"\"\"Returns actions for given state as per current policy.\n",
        "        \n",
        "        Params\n",
        "        ======\n",
        "            state (array_like): current state\n",
        "            eps (float): epsilon, for epsilon-greedy action selection\n",
        "        \"\"\"\n",
        "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
        "        self.qnetwork_local.eval()\n",
        "        with torch.no_grad():\n",
        "            action_values = self.qnetwork_local(state)\n",
        "        self.qnetwork_local.train()\n",
        "\n",
        "        # Epsilon-greedy action selection\n",
        "        if random.random() > eps:\n",
        "            return np.argmax(action_values.cpu().data.numpy())\n",
        "        else:\n",
        "            return random.choice(np.arange(self.action_size))\n",
        "\n",
        "    def learn(self, sampling, gamma):\n",
        "        \"\"\"Update value parameters using given batch of experience tuples.\n",
        "        Params\n",
        "        ======\n",
        "            sampling (Tuple[torch.Tensor]): tuple of (s, a, r, s', done) tuples \n",
        "            gamma (float): discount factor\n",
        "        \"\"\"\n",
        "        states, actions, rewards, next_states, dones, weights, indices  = sampling\n",
        "\n",
        "        ## TODO: compute and minimize the loss        \n",
        "        q_target = self.qnetwork_target(next_states).detach().max(1)[0].unsqueeze(1)\n",
        "        expected_values = rewards + gamma*q_target*(1-dones)\n",
        "        output = self.qnetwork_local(states).gather(1, actions)\n",
        "        loss = F.mse_loss(output, expected_values)\n",
        "        if self.compute_weights:\n",
        "            with torch.no_grad():\n",
        "                weight = sum(np.multiply(weights, loss.data.cpu().numpy()))\n",
        "            loss *= weight\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        # ------------------- update target network ------------------- #\n",
        "        self.soft_update(self.qnetwork_local, self.qnetwork_target, TAU)\n",
        "\n",
        "        # ------------------- update priorities ------------------- #\n",
        "        delta = abs(expected_values - output.detach()).numpy()\n",
        "        #print(\"delta\", delta)      \n",
        "        self.memory.update_priorities(delta, indices)  \n",
        "\n",
        "    def soft_update(self, local_model, target_model, tau):\n",
        "        \"\"\"Soft update model parameters.\n",
        "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
        "        Params\n",
        "        ======\n",
        "            local_model (PyTorch model): weights will be copied from\n",
        "            target_model (PyTorch model): weights will be copied to\n",
        "            tau (float): interpolation parameter \n",
        "        \"\"\"\n",
        "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
        "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)"
      ],
      "metadata": {
        "id": "jaSq67voT3AR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train agent\n",
        "\n",
        "env = gym.make('LunarLander-v2')\n",
        "env.seed(0)\n",
        "\n",
        "agent = Agent(state_size=8, action_size=4, seed=0)\n",
        "\n",
        "def dqn(n_episodes=1000, max_t=2000, eps_start=1.0, eps_end=0.001, eps_decay=0.995):\n",
        "    \"\"\"Deep Q-Learning.\n",
        "    \n",
        "    Params\n",
        "    ======\n",
        "        n_episodes (int): maximum number of training episodes\n",
        "        max_t (int): maximum number of timesteps per episode\n",
        "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
        "        eps_end (float): minimum value of epsilon\n",
        "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
        "    \"\"\"\n",
        "    scores = []                        # list containing scores from each episode\n",
        "    scores_window = deque(maxlen=100)  # last 100 scores\n",
        "    eps = eps_start                    # initialize epsilon\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i_episode in range(1, n_episodes+1):\n",
        "        state = env.reset()\n",
        "        score = 0\n",
        "        for t in range(max_t):\n",
        "            action = agent.act(state, eps)\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "            agent.step(state, action, reward, next_state, done)\n",
        "            state = next_state\n",
        "            score += reward\n",
        "            if done:\n",
        "                break \n",
        "        scores_window.append(score)       # save most recent score\n",
        "        scores.append(score)              # save most recent score\n",
        "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
        "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
        "        if i_episode % 100 == 0:\n",
        "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
        "            elapsed_time = time.time() - start_time\n",
        "            print(\"Duration: \", elapsed_time)\n",
        "        if np.mean(scores_window)>=200.0:\n",
        "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
        "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
        "            break\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(\"Training duration: \", elapsed_time)\n",
        "    return scores\n",
        "\n",
        "\n",
        "scores = dqn()\n",
        "\n",
        "\n",
        "# plot the scores\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "plt.plot(np.arange(len(scores)), scores)\n",
        "plt.ylabel('Score')\n",
        "plt.xlabel('Episode #')\n",
        "plt.savefig('training_result.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iUxVEkuiU7Fc",
        "outputId": "d233fa85-2152-4ccf-c5ce-043b691e300e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 30\tAverage Score: -174.50sum_prob before 1.0280989276355106\n",
            "sum_prob after :  1.0000000000000013\n",
            "Episode 58\tAverage Score: -148.69sum_prob before 1.0172098507122156\n",
            "sum_prob after :  1.0000000000000018\n",
            "Episode 83\tAverage Score: -139.31sum_prob before 1.0191777239413244\n",
            "sum_prob after :  1.000000000000001\n",
            "Episode 100\tAverage Score: -133.18\n",
            "Duration:  56.14705491065979\n",
            "Episode 110\tAverage Score: -120.89sum_prob before 1.010158153980484\n",
            "sum_prob after :  0.9999999999999911\n",
            "Episode 133\tAverage Score: -111.59sum_prob before 1.013666820314572\n",
            "sum_prob after :  0.9999999999999978\n",
            "Episode 151\tAverage Score: -109.85sum_prob before 1.0134120835267646\n",
            "sum_prob after :  0.9999999999999961\n",
            "Episode 170\tAverage Score: -101.68sum_prob before 1.0148759711769637\n",
            "sum_prob after :  0.9999999999999971\n",
            "Episode 181\tAverage Score: -100.01sum_prob before 1.0157087085007719\n",
            "sum_prob after :  1.000000000000004\n",
            "Episode 194\tAverage Score: -97.43sum_prob before 1.0195171041863296\n",
            "sum_prob after :  1.000000000000001\n",
            "Episode 200\tAverage Score: -102.73\n",
            "Duration:  165.02945613861084\n",
            "Episode 207\tAverage Score: -98.09sum_prob before 1.0164706846695961\n",
            "sum_prob after :  0.9999999999999967\n",
            "Episode 214\tAverage Score: -97.84sum_prob before 1.027390160163482\n",
            "sum_prob after :  0.9999999999999997\n",
            "Episode 223\tAverage Score: -96.87sum_prob before 1.0284321827488174\n",
            "sum_prob after :  0.9999999999999878\n",
            "Episode 232\tAverage Score: -93.68sum_prob before 1.0137299106972772\n",
            "sum_prob after :  1.0000000000000018\n",
            "Episode 242\tAverage Score: -82.02sum_prob before 1.012922181386265\n",
            "sum_prob after :  1.0000000000000089\n",
            "Episode 248\tAverage Score: -81.81sum_prob before 1.0181870821063064\n",
            "sum_prob after :  1.0000000000000178\n",
            "Episode 256\tAverage Score: -78.31sum_prob before 1.0171679215185314\n",
            "sum_prob after :  0.999999999999992\n",
            "Episode 271\tAverage Score: -78.16sum_prob before 1.0154571229581808\n",
            "sum_prob after :  0.9999999999999948\n",
            "Episode 275\tAverage Score: -77.89sum_prob before 1.0134388521969495\n",
            "sum_prob after :  1.00000000000001\n",
            "Episode 279\tAverage Score: -79.09sum_prob before 1.0185242725073431\n",
            "sum_prob after :  0.9999999999999954\n",
            "Episode 286\tAverage Score: -78.76sum_prob before 1.012917365270132\n",
            "sum_prob after :  0.9999999999999907\n",
            "Episode 292\tAverage Score: -78.29sum_prob before 1.0147088672231197\n",
            "sum_prob after :  0.999999999999996\n",
            "Episode 296\tAverage Score: -73.29sum_prob before 1.0102274424196616\n",
            "sum_prob after :  1.0000000000000056\n",
            "Episode 300\tAverage Score: -69.43\n",
            "Duration:  468.591126203537\n",
            "sum_prob before 1.0143853519740833\n",
            "sum_prob after :  1.0000000000000193\n",
            "Episode 305\tAverage Score: -68.41sum_prob before 1.0165718633241125\n",
            "sum_prob after :  1.0000000000000047\n",
            "Episode 308\tAverage Score: -67.71sum_prob before 1.0125187739784316\n",
            "sum_prob after :  1.0000000000000095\n",
            "Episode 313\tAverage Score: -69.29sum_prob before 1.0127850823809756\n",
            "sum_prob after :  0.9999999999999942\n",
            "Episode 319\tAverage Score: -67.93sum_prob before 1.0119312840957675\n",
            "sum_prob after :  1.000000000000015\n",
            "Episode 322\tAverage Score: -66.67sum_prob before 1.0180082214474242\n",
            "sum_prob after :  1.0000000000000036\n",
            "Episode 325\tAverage Score: -66.84sum_prob before 1.0109775110321597\n",
            "sum_prob after :  1.0000000000000135\n",
            "Episode 329\tAverage Score: -63.44sum_prob before 1.0113058120458178\n",
            "sum_prob after :  1.000000000000004\n",
            "Episode 333\tAverage Score: -62.92sum_prob before 1.0131043058744762\n",
            "sum_prob after :  1.0000000000000024\n",
            "Episode 338\tAverage Score: -65.31sum_prob before 1.0150635421828402\n",
            "sum_prob after :  0.9999999999999815\n",
            "Episode 341\tAverage Score: -63.60sum_prob before 1.0128168899850063\n",
            "sum_prob after :  0.9999999999999984\n",
            "Episode 345\tAverage Score: -62.37sum_prob before 0.9983940578438116\n",
            "sum_prob after :  1.0000000000000135\n",
            "Episode 351\tAverage Score: -59.08sum_prob before 0.9974699836464122\n",
            "sum_prob after :  1.0000000000000127\n",
            "Episode 354\tAverage Score: -58.29sum_prob before 1.001052240539721\n",
            "sum_prob after :  1.00000000000003\n",
            "Episode 358\tAverage Score: -54.51sum_prob before 1.001829321851317\n",
            "sum_prob after :  0.9999999999999939\n",
            "Episode 361\tAverage Score: -52.86sum_prob before 0.9993824534511041\n",
            "sum_prob after :  1.0000000000000124\n",
            "Episode 364\tAverage Score: -49.42sum_prob before 0.9960943620687567\n",
            "sum_prob after :  1.000000000000007\n",
            "Episode 370\tAverage Score: -47.31sum_prob before 1.0007267001585967\n",
            "sum_prob after :  1.0000000000000184\n",
            "Episode 374\tAverage Score: -46.95sum_prob before 0.9984847837381509\n",
            "sum_prob after :  1.0000000000000029\n",
            "Episode 377\tAverage Score: -40.64sum_prob before 0.9975599879946855\n",
            "sum_prob after :  1.0000000000000078\n",
            "Episode 380\tAverage Score: -35.75sum_prob before 1.0003306664662903\n",
            "sum_prob after :  0.9999999999999747\n",
            "Episode 384\tAverage Score: -39.52sum_prob before 0.9982295871299207\n",
            "sum_prob after :  1.000000000000026\n",
            "Episode 388\tAverage Score: -30.19sum_prob before 0.9973946915987566\n",
            "sum_prob after :  1.0000000000000053\n",
            "Episode 392\tAverage Score: -22.86sum_prob before 0.9959759956601388\n",
            "sum_prob after :  0.9999999999999726\n",
            "Episode 395\tAverage Score: -19.55sum_prob before 1.0025998224089518\n",
            "sum_prob after :  0.9999999999999909\n",
            "Episode 400\tAverage Score: -16.05\n",
            "Duration:  1163.724273443222\n",
            "Episode 401\tAverage Score: -18.65sum_prob before 0.9982198899438678\n",
            "sum_prob after :  1.0000000000000264\n",
            "Episode 406\tAverage Score: -15.22sum_prob before 1.0003371635335023\n",
            "sum_prob after :  0.9999999999999588\n",
            "Episode 410\tAverage Score: -12.06sum_prob before 0.9976756481847849\n",
            "sum_prob after :  1.000000000000011\n",
            "Episode 418\tAverage Score: 0.88sum_prob before 0.9997395403540004\n",
            "sum_prob after :  0.9999999999999526\n",
            "Episode 424\tAverage Score: 8.55sum_prob before 0.9998393414757226\n",
            "sum_prob after :  1.0000000000000044\n",
            "Episode 430\tAverage Score: 13.64sum_prob before 1.0002892225873494\n",
            "sum_prob after :  1.0000000000000044\n",
            "Episode 436\tAverage Score: 22.12sum_prob before 1.0018040948142035\n",
            "sum_prob after :  0.9999999999999752\n",
            "Episode 443\tAverage Score: 31.49sum_prob before 0.9971162794838432\n",
            "sum_prob after :  0.9999999999999793\n",
            "Episode 450\tAverage Score: 46.26sum_prob before 1.0009054899035197\n",
            "sum_prob after :  0.999999999999988\n",
            "Episode 456\tAverage Score: 50.62sum_prob before 1.0013413934579372\n",
            "sum_prob after :  0.9999999999999765\n",
            "Episode 463\tAverage Score: 56.18sum_prob before 1.0011745871178614\n",
            "sum_prob after :  1.000000000000026\n",
            "Episode 469\tAverage Score: 63.63sum_prob before 1.0002589041007957\n",
            "sum_prob after :  1.0000000000000326\n",
            "Episode 474\tAverage Score: 68.06sum_prob before 0.9996942569302811\n",
            "sum_prob after :  1.0000000000000309\n",
            "Episode 479\tAverage Score: 71.88sum_prob before 1.0020744893960054\n",
            "sum_prob after :  0.9999999999999882\n",
            "Episode 486\tAverage Score: 77.57sum_prob before 1.0006803102202875\n",
            "sum_prob after :  1.0000000000000553\n",
            "Episode 495\tAverage Score: 88.09sum_prob before 0.9987615409305417\n",
            "sum_prob after :  1.0000000000000153\n",
            "Episode 500\tAverage Score: 99.25\n",
            "Duration:  1576.751900434494\n",
            "Episode 505\tAverage Score: 111.66sum_prob before 1.0015196214566469\n",
            "sum_prob after :  0.9999999999999896\n",
            "Episode 511\tAverage Score: 123.04sum_prob before 0.9984441221396884\n",
            "sum_prob after :  0.9999999999999815\n",
            "Episode 520\tAverage Score: 118.70sum_prob before 1.0030269467356991\n",
            "sum_prob after :  1.0000000000000056\n",
            "Episode 528\tAverage Score: 123.52sum_prob before 0.9999073014378578\n",
            "sum_prob after :  1.0000000000000058\n",
            "Episode 533\tAverage Score: 122.60sum_prob before 0.9996190962569929\n",
            "sum_prob after :  1.0000000000000004\n",
            "Episode 540\tAverage Score: 126.45sum_prob before 0.9976826340168706\n",
            "sum_prob after :  1.0000000000000016\n",
            "Episode 549\tAverage Score: 133.39sum_prob before 0.9982599736820424\n",
            "sum_prob after :  1.000000000000005\n",
            "Episode 555\tAverage Score: 141.58sum_prob before 0.9993162057349135\n",
            "sum_prob after :  1.0000000000000149\n",
            "Episode 563\tAverage Score: 149.70sum_prob before 0.9982804784224169\n",
            "sum_prob after :  0.9999999999999951\n",
            "Episode 570\tAverage Score: 152.93sum_prob before 1.0016823774323496\n",
            "sum_prob after :  1.0000000000000004\n",
            "Episode 577\tAverage Score: 164.34sum_prob before 0.9966748027574222\n",
            "sum_prob after :  0.9999999999999785\n",
            "Episode 585\tAverage Score: 178.61sum_prob before 1.0041952298137418\n",
            "sum_prob after :  0.9999999999999747\n",
            "Episode 596\tAverage Score: 167.75sum_prob before 1.0001956856176053\n",
            "sum_prob after :  0.9999999999999937\n",
            "Episode 600\tAverage Score: 166.50\n",
            "Duration:  1918.0908966064453\n",
            "Episode 603\tAverage Score: 166.86sum_prob before 0.9998498587453977\n",
            "sum_prob after :  0.9999999999999833\n",
            "Episode 609\tAverage Score: 158.08sum_prob before 1.0005508536231467\n",
            "sum_prob after :  0.9999999999999688\n",
            "Episode 617\tAverage Score: 172.24sum_prob before 1.001742060250099\n",
            "sum_prob after :  1.0000000000000218\n",
            "Episode 624\tAverage Score: 178.36sum_prob before 1.0036971124210743\n",
            "sum_prob after :  0.9999999999999806\n",
            "Episode 630\tAverage Score: 184.68sum_prob before 0.9979531766730012\n",
            "sum_prob after :  0.9999999999999699\n",
            "Episode 639\tAverage Score: 187.97sum_prob before 0.9973191743961145\n",
            "sum_prob after :  1.0000000000000033\n",
            "Episode 648\tAverage Score: 189.94sum_prob before 0.9986389912127923\n",
            "sum_prob after :  0.9999999999999775\n",
            "Episode 658\tAverage Score: 194.98sum_prob before 0.9977591090957233\n",
            "sum_prob after :  0.9999999999999827\n",
            "Episode 660\tAverage Score: 200.68\n",
            "Environment solved in 560 episodes!\tAverage Score: 200.68\n",
            "Training duration:  2114.4821560382843\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}